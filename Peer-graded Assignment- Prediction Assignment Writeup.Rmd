---
title: 'Peer-graded Assignment: Prediction Assignment Writeup'
author: "Mehul Arora"
date: 'October 18, 2020'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Background

It is possible to collect a lot of data by using devices like Jawbone, FuelBand, and Fitbit. The data can be about personal activity relatively inexpensively. The measurements are takein by enthusiasts who regularly to improve their health, to find patterns in their behavior. It can be possible becauseor they are tech enthusiasts. An intergral that people regularly do is quantify how much of that activity they usually do, but they rarely quantify how good they are in it. The goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants in this project. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).


#Objective

Predict the manner in which they did the exercise is the goal of the project. This is the "classe" variable in the training set. You may use any of the other variables to predict with. Then a report has to be created to describe how the model is being built, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

#Data

The data for training of this project is:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data is,

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

#Load the data

```{r, results=FALSE}
library(caret)
library(Hmisc)
library(corrplot)
library(e1071)
```

First we download our data and we read them in R.

```{r}
set.seed(2343)
fileUrltrain<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
fileUrltest<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrltrain, destfile = "~/Desktop/Rprogramming/train.csv", method="curl")
download.file(fileUrltest, destfile = "~/Desktop/Rprogramming/test.csv", method="curl")
train = read.csv("train.csv")
quiz = read.csv("test.csv")
```

We take a look at data to see what kind of cleaning we need to do.

```{r}
set.seed(2343)
summary(train)
str(train)
```

#Clenings

With the help of the function summary and str we could find that the data have have the following problems: a. presence of some characters such as "#DIV/0!". b. Many variables have a lot of NA values. c. We hane quite a few near-zero-variance variables.

```{r}
set.seed(2343)
train = read.csv("train.csv", na.strings=c("#DIV/0!"))
train.nZV <- nearZeroVar(train)
train<-train[ , -train.nZV]
variables <- colnames(train[colSums(is.na(train)) == 0])
data1<- train[variables]
working.data <- data1[ , -(1:6)]
dim(working.data)
```

#Data partition and correlation

The  original daaset is seperated into a training set and a testing set for cross validation. We choose 70\% of our original data to be the training set and 30\% the testing set.

The correlation between the variables is checked: 

```{r}
set.seed(2343)
inTrain <- createDataPartition(y=working.data$classe, p=0.7, list=FALSE )
training <- working.data[inTrain,]
testing <- working.data[-inTrain,]
M <- cor(training[ , -53])
corrplot(M, order = "FPC", method = "square")
```

Variables that are highly correlated appear with darker colour (red or blue). Most of the input variables have weak correlation (if any). Therefore we will proceed with the modeling but, have a few different prediction models.


#Model selection

Three different methods are used and calculated to treir confussion matrix to find their accuracy.

a. Support Vector Machine:


```{r}
set.seed(2343)
fit1 <- svm(classe ~ ., data = training)
predict1 <- predict(fit1, newdata = testing)
confusionMatrix(predict1, testing$classe)
```

b. Generalized Boosted Model:

```{r}
set.seed(2343)
TCgbm <- trainControl(method = "repeatedcv", number = 5, repeats = 2)
fit2  <- train(classe ~ ., data = training, method = "gbm",
                  trControl = TCgbm, verbose = FALSE)
predict2<- predict(fit2, newdata = testing)
confusionMatrix(predict2, testing$classe)
```

c. Random Forest:

```{r}
set.seed(2343)
TCrf <- trainControl(method = "repeatedcv", number = 5, repeats = 2)
fit3  <- train(classe ~ ., data = training, method = "rf",
                  trControl = TCrf, verbose = FALSE)
predict3 <- predict(fit3, newdata = testing)
confusionMatrix(predict3, testing$classe)
```

The first model the Support Vector Machine has accuracy of 95.4\%. The next model the Generalized Boosted Model has accuracy of 96.1\%. Finally our last model has accuracy of 99.4\%. Now it is seen what is the out-of-sample error for our last and most accurate model.


#Out-of-sample error

```{r}
set.seed(2343)
out.of.sample.error = function(values, predicted) {
  sum(predicted != values) / length(values)
}
out.of.sample.error(testing$classe, predict3)
```

The out-of-sample error for our last and most accurate model is 0.6\% as we would expect.

#Conclusion

In this project data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to see how well they do the exercises has been used. The fact that we found three models with accuracy above 95\% is quite impressive. This result indicates that the participates were really serious and dedicated to do the exercises properly.
